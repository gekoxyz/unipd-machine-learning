{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                        4\n",
      "workclass                  0\n",
      "fnlwgt                     0\n",
      "education                  0\n",
      "education_num              0\n",
      "marital_status             0\n",
      "occupation                 0\n",
      "relationship               0\n",
      "race                       0\n",
      "sex                        0\n",
      "capital_gain               0\n",
      "capital_loss               0\n",
      "hours_per_week             0\n",
      "native_country             0\n",
      "income_greater_than_50k    0\n",
      "dtype: int64\n",
      "age                        0\n",
      "workclass                  0\n",
      "fnlwgt                     0\n",
      "education                  0\n",
      "education_num              0\n",
      "marital_status             0\n",
      "occupation                 0\n",
      "relationship               0\n",
      "race                       0\n",
      "sex                        0\n",
      "capital_gain               0\n",
      "capital_loss               0\n",
      "hours_per_week             0\n",
      "native_country             0\n",
      "income_greater_than_50k    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "DATASET_PATH = \"./income_dataset.csv\"\n",
    "df = pd.read_csv(DATASET_PATH, sep=\",\")\n",
    "\n",
    "# handle null values in the dataset\n",
    "df.replace('?', np.nan)\n",
    "df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "\n",
    "# replace null values with the median\n",
    "print(df.isnull().sum())\n",
    "df = df.apply(lambda x: x.fillna(x.median()) if is_numeric_dtype(x) else x.fillna(x.mode().iloc[0]))\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical features: one-hot encoding (create a binary vector for each category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "748\n"
     ]
    }
   ],
   "source": [
    "# get all columns which are not numeric and not the loan status\n",
    "categorical_features = [col for col in df.columns if not is_numeric_dtype(df[col])]\n",
    "df_onehot = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "print(df[\"income_greater_than_50k\"].value_counts()[1])\n",
    "print(df[\"income_greater_than_50k\"].value_counts()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (800, 89)\n",
      "Test set shape (200, 89)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# use the index location function on all the rows and all the columns\n",
    "# except the last one\n",
    "X = df_onehot.iloc[:, :-1]\n",
    "\n",
    "y = df_onehot.income_greater_than_50k\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337, stratify=y, shuffle=True)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** performance on the test set *****\n",
      "accuracy = 0.795\n",
      "***** classification report *****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.95      0.87       150\n",
      "           1       0.70      0.32      0.44        50\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.75      0.64      0.66       200\n",
      "weighted avg       0.78      0.80      0.77       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(true_values, predicted_values):\n",
    "  print(f\"accuracy = {accuracy_score(true_values, predicted_values):.3f}\")\n",
    "\n",
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"***** performance on the test set *****\")\n",
    "evaluate(y_test, model.predict(X_test))\n",
    "\n",
    "print(f\"***** classification report *****\")\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Evaluate Average Performance on Cross-Validation Set *****\n",
      "Avg. Test Set Accuracy = 0.822\n"
     ]
    }
   ],
   "source": [
    "# model evaluation using cross-validation\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=1337)\n",
    "cv = cross_validate(model, X, y, cv=k_fold, scoring=(\"roc_auc\", \"accuracy\"), return_train_score=True)\n",
    "pd.DataFrame(cv)\n",
    "print(\"***** Evaluate Average Performance on Cross-Validation Set *****\")\n",
    "print(\"Avg. Test Set Accuracy = {:.3f}\".format(np.mean(cv[\"test_accuracy\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find the best hyperparameter for a model (the code works also for a family of models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Evaluate Performance on Validation Set *****\n",
      "{'C': {0.01: 0.8, 0.05: 0.8, 0.1: 0.8, 0.5: 0.8, 1: 0.8, 2: 0.8}}\n",
      "***** Best Accuracy Score on Validation Set *****\n",
      "{'C': (0.01, 0.8)}\n",
      "***** Evaluate Performance on the whole Test Set *****\n",
      "accuracy = 0.795\n"
     ]
    }
   ],
   "source": [
    "models_hyperparams = {\n",
    "  \"LogisticRegression\" : (\n",
    "    LogisticRegression(solver=\"liblinear\"),\n",
    "    {\"C\" : [0.01, 0.05, 0.1, 0.5, 1, 2]}\n",
    "  )\n",
    "}\n",
    "\n",
    "X_dataset, X_test, y_dataset, y_test = train_test_split(X, y, test_size=0.2, random_state=1337, stratify=y)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_dataset, y_dataset, test_size=0.2, random_state=1337, stratify=y_dataset)\n",
    "\n",
    "validation_scores = {}\n",
    "best_validation_score = {}\n",
    "\n",
    "model = models_hyperparams[\"LogisticRegression\"][0]\n",
    "hyperparams = models_hyperparams[\"LogisticRegression\"][1]\n",
    "\n",
    "for hp in hyperparams:\n",
    "  validation_scores[hp] = {}\n",
    "\n",
    "  for val in hyperparams[hp]:\n",
    "    model.set_params(**{hp: val})\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    validation_score = accuracy_score(y_validation, model.predict(X_validation))\n",
    "    validation_scores[hp][val] = validation_score\n",
    "\n",
    "    if not best_validation_score:\n",
    "      best_validation_score[hp] = (val, validation_score)\n",
    "    else:\n",
    "      if best_validation_score[hp][1] < validation_score:\n",
    "        best_validation_score[hp] = (val, validation_score)\n",
    "\n",
    "print(\"***** Evaluate Performance on Validation Set *****\")\n",
    "print(validation_scores)\n",
    "print(\"***** Best Accuracy Score on Validation Set *****\")\n",
    "print(best_validation_score)\n",
    "\n",
    "# we set the model's hyperparameters to those leading to the best score on the validation test\n",
    "best_params = dict([(list(best_validation_score.keys())[0], list(best_validation_score.values())[0][0])])\n",
    "model.set_params(**best_params)\n",
    "\n",
    "# we fit this model to the whole training set portion\n",
    "model.fit(X_train, y_train)\n",
    "print(\"***** Evaluate Performance on the whole Test Set *****\")\n",
    "evaluate(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross-validation to find the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "Best hyperparameter: {'C': 0.05}\n",
      "Best accuracy score: 0.818\n",
      "accuracy = 0.795\n"
     ]
    }
   ],
   "source": [
    "models_and_hyperparams = {\n",
    "  \"LogisticRegression\": (\n",
    "    LogisticRegression(solver=\"liblinear\"),\n",
    "    {\"C\": [0.01, 0.05, 0.1, 0.5, 1, 2]},\n",
    "  )\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.2, random_state=1337, stratify=y\n",
    ")\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1337)\n",
    "\n",
    "model = models_and_hyperparams[\"LogisticRegression\"][0]\n",
    "hyperparams = models_and_hyperparams[\"LogisticRegression\"][1]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "  estimator=model,\n",
    "  param_grid=hyperparams,\n",
    "  cv=k_fold,\n",
    "  scoring=\"accuracy\",\n",
    "  verbose=True,\n",
    "  return_train_score=True,\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "pd.DataFrame(gs.cv_results_)\n",
    "\n",
    "print(f\"Best hyperparameter: {gs.best_params_}\")\n",
    "print(f\"Best accuracy score: {gs.best_score_:.3f}\")\n",
    "evaluate(y_test, gs.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
